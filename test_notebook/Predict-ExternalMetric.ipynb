{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497a5903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import torch\n",
    "import json\n",
    "sys.path.append('../')\n",
    "from models.utils import rocksdb_knobs_make_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a34fcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_internal = \"../data/internal\"\n",
    "PATH_external = \"../data/external\"\n",
    "PATH_knobs = \"../data/rocksdb_conf\"\n",
    "wk_len = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c05bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "knobs = rocksdb_knobs_make_dict(PATH_knobs)\n",
    "knobs = pd.DataFrame(data=knobs['data'].astype(np.float32), columns=knobs['columnlabels'])\n",
    "columns = knobs.columns\n",
    "knobs.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff92812",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "knobs[:128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001e4aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(knobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed78963",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "knobs.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d362eecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wk_len = 16\n",
    "internal_dict = {}\n",
    "\n",
    "pruned_im = pd.read_csv(os.path.join(PATH_internal, 'internal_ensemble_pruned_tmp.csv'), index_col=0)\n",
    "for wk in range(wk_len):\n",
    "    im = pd.read_csv(os.path.join(PATH_internal, f'internal_results_{wk}.csv'), index_col=0)\n",
    "    internal_dict[wk] = im[pruned_im.columns]\n",
    "#     break\n",
    "internal_dict[0].head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bc584d",
   "metadata": {},
   "outputs": [],
   "source": [
    "external_dict = {}\n",
    "for wk in range(wk_len):\n",
    "    ex = pd.read_csv(os.path.join(PATH_external, f'external_results_{wk}.csv'), index_col=0)\n",
    "    external_dict[wk] = ex\n",
    "#     break\n",
    "external_dict[0].head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa739556",
   "metadata": {},
   "source": [
    "## Test Train\n",
    "- train: 16000, test: 4000\n",
    "- target: 0 th workload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e90336",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from models.network import RocksDBDataset, SingleNet#, EncoderRNN, DecoderRNN\n",
    "from models.train import train, valid#, trainRNN, validRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed8b621",
   "metadata": {},
   "outputs": [],
   "source": [
    "knobOneHot = np.load('../data/knobsOneHot.npy')\n",
    "internal_m = internal_dict[2] # similar datasets\n",
    "external_m = external_dict[2] # similar datasets\n",
    "knobOneHot.shape, internal_m.shape, external_m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420c7d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_te, Im_tr, Im_te, y_tr, y_te, knob_tr, knob_te = \\\n",
    "            train_test_split(knobOneHot, internal_m, external_m, knobs, test_size=0.2, random_state=24)\n",
    "X_tr.shape, X_te.shape, Im_tr.shape, Im_te.shape, y_tr.shape, y_te.shape, knob_tr.shape, knob_te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cd52ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_te.to_numpy()[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb231188",
   "metadata": {},
   "outputs": [],
   "source": [
    "Im_tr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64ab563",
   "metadata": {},
   "source": [
    "### Pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a67cd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_X = MinMaxScaler().fit(X_tr) # range: 0~1\n",
    "scaler_knob = MinMaxScaler().fit(knob_tr)\n",
    "scaler_Im = MinMaxScaler().fit(Im_tr)\n",
    "scaler_y = StandardScaler().fit(y_tr)\n",
    "\n",
    "# X_norm_tr = torch.Tensor(scaler_X.transform(X_tr)).cuda()\n",
    "# X_norm_te = torch.Tensor(scaler_X.transform(X_te)).cuda()\n",
    "X_tr = torch.Tensor(X_tr).cuda()\n",
    "X_te = torch.Tensor(X_te).cuda()\n",
    "y_norm_tr = torch.Tensor(scaler_y.transform(y_tr)).cuda()\n",
    "y_norm_te = torch.Tensor(scaler_y.transform(y_te)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3636eadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Im_norm_tr = torch.Tensor(scaler_Im.transform(Im_tr)).cuda()\n",
    "Im_norm_te = torch.Tensor(scaler_Im.transform(Im_te)).cuda()\n",
    "Dataset_tr = RocksDBDataset(X_tr, Im_norm_tr)\n",
    "Dataset_te = RocksDBDataset(X_te, Im_norm_te)\n",
    "\n",
    "loader_tr = DataLoader(dataset = Dataset_tr, batch_size = 32, shuffle=True)\n",
    "loader_te = DataLoader(dataset = Dataset_te, batch_size = 32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9afcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "k2i_model = SingleNet(input_dim=X_tr.shape[1], hidden_dim=1024, output_dim=148).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a998a4a8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "epochs = 30\n",
    "losses_tr = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss_tr = train(k2i_model, loader_tr, lr)\n",
    "    losses_tr.append(loss_tr)\n",
    "\n",
    "    print(f\"[{epoch:02d}/{epochs}] loss_tr: {loss_tr}\")\n",
    "        \n",
    "# print(f\"[{epoch:02d}/{epochs}] loss_tr: {loss_tr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922ffb5b",
   "metadata": {},
   "source": [
    "### Train with knob2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad7e220",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lookup_table = k2i_model.knob_fc[0].weight.T.cpu().detach().numpy()\n",
    "# lookup_table = np.load('LookupTable.npy')\n",
    "lookup_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fbef15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('LookupTable.npy', lookup_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e41d453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_knob2vec(data, table):\n",
    "    k2vec = np.zeros((data.shape[0], 22, table.shape[1]))\n",
    "    for i in range(data.shape[0]):\n",
    "#         idx = (data[i]==1).nonzero().squeeze().cpu().detach().numpy()\n",
    "        idx = (data[i]==1).nonzero().squeeze().cpu().detach().numpy()\n",
    "        k2vec[i] = lookup_table[idx]\n",
    "    return k2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d46b3d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "K2vec_tr = torch.Tensor(get_knob2vec(X_tr, lookup_table)).cuda()\n",
    "K2vec_tr = torch.reshape(K2vec_tr, (K2vec_tr.shape[0], -1))\n",
    "K2vec_te = torch.Tensor(get_knob2vec(X_te, lookup_table)).cuda()\n",
    "K2vec_te = torch.reshape(K2vec_te, (K2vec_te.shape[0], -1))\n",
    "\n",
    "Dataset_K2vec_tr = RocksDBDataset(K2vec_tr, y_norm_tr)\n",
    "Dataset_K2vec_te = RocksDBDataset(K2vec_te, y_norm_te)\n",
    "\n",
    "loader_K2vec_tr = DataLoader(dataset = Dataset_K2vec_tr, batch_size = 32, shuffle=True)\n",
    "loader_K2vec_te = DataLoader(dataset = Dataset_K2vec_te, batch_size = 32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826e6933",
   "metadata": {},
   "outputs": [],
   "source": [
    "K2vec_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59b4389",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SingleNet(input_dim=K2vec_tr.shape[-1], hidden_dim=64, output_dim=4).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566a6bff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "epochs = 30\n",
    "losses_tr = []\n",
    "losses_te = []\n",
    "for epoch in range(epochs):\n",
    "    loss_tr = train(model, loader_K2vec_tr, lr)\n",
    "    loss_te, outputs = valid(model, loader_K2vec_te)\n",
    "    \n",
    "    losses_tr.append(loss_tr)\n",
    "    losses_te.append(loss_te)\n",
    "    \n",
    "    print(f'[{epoch}/{epochs}] loss_tr: {loss_tr:.8f}\\tloss_te:{loss_te:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4151390e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.round(scaler_y.inverse_transform(outputs.cpu().detach().numpy()),2)\n",
    "true = y_te.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da566d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cfd965",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(f'predict rslt: {pred[i]}')\n",
    "    print(f'ground truth: {true[i]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb82c10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in external_dict[0].columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c0856b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score = r2_score(true, pred, multioutput='raw_values')\n",
    "ex_col = external_dict[0].columns\n",
    "for i, c in enumerate(ex_col):\n",
    "    print(f'{c:4} r2 score = {score[i]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6952833",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r2_score(true, pred, multioutput='raw_values')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31d29a7",
   "metadata": {},
   "source": [
    "### Train with knob2vec and GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0424634",
   "metadata": {},
   "outputs": [],
   "source": [
    "K2vec_tr = torch.Tensor(get_knob2vec(X_tr, lookup_table)).cuda()\n",
    "K2vec_te = torch.Tensor(get_knob2vec(X_te, lookup_table)).cuda()\n",
    "\n",
    "Dataset_K2vec_tr = RocksDBDataset(K2vec_tr, y_norm_tr)\n",
    "Dataset_K2vec_te = RocksDBDataset(K2vec_te, y_norm_te)\n",
    "\n",
    "loader_K2vec_tr = DataLoader(dataset = Dataset_K2vec_tr, batch_size = 32, shuffle=True)\n",
    "loader_K2vec_te = DataLoader(dataset = Dataset_K2vec_te, batch_size = 32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34a20c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderRNN(hidden_dim=K2vec_tr.shape[-1]).cuda()\n",
    "decoder = DecoderRNN(hidden_dim=K2vec_tr.shape[-1], output_dim=1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0361f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "epochs = 30\n",
    "losses_tr = []\n",
    "losses_te = []\n",
    "for epoch in range(epochs):\n",
    "    loss_tr = trainRNN(encoder, decoder, loader_K2vec_tr, lr)\n",
    "    loss_te = validRNN(encoder, decoder, loader_K2vec_te)\n",
    "    \n",
    "    losses_tr.append(loss_tr)\n",
    "    losses_te.append(loss_te)\n",
    "    \n",
    "    print(f\"[{epoch:02d}/{epochs}] loss_tr: {loss_tr}\\tloss_te:{loss_te:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c1edeb",
   "metadata": {},
   "source": [
    "### Train with raw knob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3857a756",
   "metadata": {},
   "outputs": [],
   "source": [
    "knob_norm_tr = torch.Tensor(scaler_knob.transform(knob_tr)).cuda()\n",
    "knob_norm_te = torch.Tensor(scaler_knob.transform(knob_te)).cuda()\n",
    "\n",
    "Dataset_knob_tr = RocksDBDataset(knob_norm_tr, y_norm_tr)\n",
    "Dataset_knob_te = RocksDBDataset(knob_norm_te, y_norm_te)\n",
    "\n",
    "loader_knob_tr = DataLoader(dataset = Dataset_knob_tr, batch_size = 32, shuffle=True)\n",
    "loader_knob_te = DataLoader(dataset = Dataset_knob_te, batch_size = 32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e93d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "knob_model = SingleNet(input_dim=knob_norm_tr.shape[1], hidden_dim=16, output_dim=4).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec51bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "epochs = 30\n",
    "losses_tr = []\n",
    "losses_te = []\n",
    "for epoch in range(epochs):\n",
    "    loss_tr = train(knob_model, loader_knob_tr, lr)\n",
    "    loss_te = valid(knob_model, loader_knob_te)\n",
    "    \n",
    "    losses_tr.append(loss_tr)\n",
    "    losses_te.append(loss_te)\n",
    "    \n",
    "    print(f\"[{epoch:02d}/{epochs}] loss_tr: {loss_tr}\\tloss_te:{loss_te:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c921e7e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(scaler_y.inverse_transform(y_norm_te.cpu().detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d626e2b3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(scaler_y.inverse_transform(model(K2vec_te).cpu().detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8c6404",
   "metadata": {},
   "outputs": [],
   "source": [
    "_30 = scaler_y.inverse_transform(knob_model(knob_norm_te).cpu().detach().numpy()) # 30\n",
    "_30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2664c6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d8b4d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(scaler_y.inverse_transform(knob_model(knob_norm_te).cpu().detach().numpy())) # 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd00179",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[py3.7]",
   "language": "python",
   "name": "py3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
